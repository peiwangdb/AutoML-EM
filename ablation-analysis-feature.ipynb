{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiwang/anaconda3/lib/python3.7/site-packages/pyparsing.py:3168: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile(self.reString)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "import autosklearn.classification\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_6 training data size: 9167 test data size: 2293\n",
      "[WARNING] [2020-10-08 14:05:54,560:EnsembleBuilder(1):4ab864c8876c543722442b506ccbf935] No models better than random - using Dummy Score!\n",
      "[WARNING] [2020-10-08 14:05:54,569:EnsembleBuilder(1):4ab864c8876c543722442b506ccbf935] No models better than random - using Dummy Score!\n",
      "[WARNING] [2020-10-08 14:27:03,072:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2020-10-08 14:27:03,072:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2020-10-08 14:40:29,255:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2020-10-08 14:40:29,255:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "\n",
      " random-forest-selected, training fscore: 0.8131241084165477 , test fscore:  0.6406570841889118 \n",
      "\n",
      "[(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'none', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'entropy', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.9950088003474201, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 6, 'classifier:random_forest:min_samples_split': 7, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'preprocessor:feature_agglomeration:affinity': 'euclidean', 'preprocessor:feature_agglomeration:linkage': 'complete', 'preprocessor:feature_agglomeration:n_clusters': 91, 'preprocessor:feature_agglomeration:pooling_func': 'max', 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.0012037695802164811},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "]\n",
      "auto-sklearn results:\n",
      "  Dataset name: 4ab864c8876c543722442b506ccbf935\n",
      "  Metric: f1\n",
      "  Best validation score: 0.628684\n",
      "  Number of target algorithm runs: 161\n",
      "  Number of successful target algorithm runs: 150\n",
      "  Number of crashed target algorithm runs: 5\n",
      "  Number of target algorithms that exceeded the time limit: 2\n",
      "  Number of target algorithms that exceeded the memory limit: 4\n",
      "\n",
      "\n",
      "\n",
      "data_7 training data size: 8193 test data size: 2049\n",
      "[WARNING] [2020-10-08 15:05:49,601:EnsembleBuilder(1):a619ef2c1fe74f7db94dc7cc716bf72b] No models better than random - using Dummy Score!\n",
      "[WARNING] [2020-10-08 15:05:49,610:EnsembleBuilder(1):a619ef2c1fe74f7db94dc7cc716bf72b] No models better than random - using Dummy Score!\n",
      "[WARNING] [2020-10-08 15:05:51,615:EnsembleBuilder(1):a619ef2c1fe74f7db94dc7cc716bf72b] No models better than random - using Dummy Score!\n",
      "[WARNING] [2020-10-08 15:50:22,143:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2020-10-08 15:50:22,143:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "\n",
      " random-forest-selected, training fscore: 0.9413298565840938 , test fscore:  0.8140161725067385 \n",
      "\n",
      "[(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'select_percentile_classification', 'rescaling:__choice__': 'robust_scaler', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.9008519355763185, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 2, 'classifier:random_forest:min_samples_split': 6, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'preprocessor:select_percentile_classification:percentile': 55.84285592896699, 'preprocessor:select_percentile_classification:score_func': 'f_classif', 'rescaling:robust_scaler:q_max': 0.9194022794180152, 'rescaling:robust_scaler:q_min': 0.19454891546620004, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.07845205738658005},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "]\n",
      "auto-sklearn results:\n",
      "  Dataset name: a619ef2c1fe74f7db94dc7cc716bf72b\n",
      "  Metric: f1\n",
      "  Best validation score: 0.813370\n",
      "  Number of target algorithm runs: 242\n",
      "  Number of successful target algorithm runs: 230\n",
      "  Number of crashed target algorithm runs: 2\n",
      "  Number of target algorithms that exceeded the time limit: 4\n",
      "  Number of target algorithms that exceeded the memory limit: 6\n",
      "\n",
      "\n",
      "\n",
      "data_8 training data size: 7659 test data size: 1916\n",
      "[WARNING] [2020-10-08 16:05:44,750:EnsembleBuilder(1):fcf3cd40185117d08e556947af92a53e] No models better than random - using Dummy Score!\n",
      "[WARNING] [2020-10-08 16:05:44,759:EnsembleBuilder(1):fcf3cd40185117d08e556947af92a53e] No models better than random - using Dummy Score!\n",
      "[WARNING] [2020-10-08 16:05:46,768:EnsembleBuilder(1):fcf3cd40185117d08e556947af92a53e] No models better than random - using Dummy Score!\n",
      "[WARNING] [2020-10-08 16:35:07,432:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2020-10-08 16:35:07,432:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2020-10-08 17:05:38,379:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2020-10-08 17:05:38,379:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "\n",
      " random-forest-selected, training fscore: 0.8630217519106408 , test fscore:  0.5857519788918206 \n",
      "\n",
      "[(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'no_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'median', 'preprocessor:__choice__': 'feature_agglomeration', 'rescaling:__choice__': 'none', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'entropy', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.9008524359169225, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 6, 'classifier:random_forest:min_samples_split': 4, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'preprocessor:feature_agglomeration:affinity': 'manhattan', 'preprocessor:feature_agglomeration:linkage': 'average', 'preprocessor:feature_agglomeration:n_clusters': 128, 'preprocessor:feature_agglomeration:pooling_func': 'max'},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "]\n",
      "auto-sklearn results:\n",
      "  Dataset name: fcf3cd40185117d08e556947af92a53e\n",
      "  Metric: f1\n",
      "  Best validation score: 0.638191\n",
      "  Number of target algorithm runs: 222\n",
      "  Number of successful target algorithm runs: 203\n",
      "  Number of crashed target algorithm runs: 8\n",
      "  Number of target algorithms that exceeded the time limit: 2\n",
      "  Number of target algorithms that exceeded the memory limit: 9\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run on extracted features\n",
    "\n",
    "for i in range(6, 9):\n",
    "    for t in [3600]:\n",
    "        train_path = './02-feature-extract-ori/features/ft_' + str(i) + '_train.csv'\n",
    "        test_path = './02-feature-extract-ori/features/ft_' + str(i) + '_test.csv'\n",
    "        \n",
    "        df_train = pd.read_csv(train_path)\n",
    "        df_test = pd.read_csv(test_path)\n",
    "        \n",
    "        X_train = np.array(df_train.drop(['label'], axis=1).values.tolist())\n",
    "        y_train = np.array(df_train['label'].values.tolist())\n",
    "        X_test = np.array(df_test.drop(['label'], axis=1).values.tolist())\n",
    "        y_test = np.array(df_test['label'].values.tolist())\n",
    "        print(\"data_\" + str(i), \"training data size:\", len(y_train), \"test data size:\", len(y_test))\n",
    "        \n",
    "        \n",
    "        automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "            include_estimators=['random_forest'], \n",
    "            time_left_for_this_task=3600, \n",
    "            initial_configurations_via_metalearning=0, \n",
    "            seed = 1,\n",
    "            ensemble_nbest=1, \n",
    "            ensemble_size=1, \n",
    "            resampling_strategy='holdout',\n",
    "            resampling_strategy_arguments={'train_size':0.75, 'random_state':42}\n",
    "        )\n",
    "        automl.fit(X_train, y_train, metric=autosklearn.metrics.f1)\n",
    "        print(\"\\n random-forest-selected, training fscore:\", automl.score(X_train, y_train),  \n",
    "              \", test fscore: \", automl.score(X_test, y_test), '\\n')\n",
    "        print(automl.show_models())\n",
    "        print(automl.sprint_statistics())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from autosklearn.pipeline.classification import SimpleClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_6 training data size: 9167 test data size: 2293\n",
      "6875 2292 2293\n"
     ]
    }
   ],
   "source": [
    "# analysis for dataset 6:\n",
    "\n",
    "i = 6\n",
    "\n",
    "train_path = './02-feature-extract-ori/features/ft_' + str(i) + '_train.csv'\n",
    "test_path = './02-feature-extract-ori/features/ft_' + str(i) + '_test.csv'\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "        \n",
    "X_train = np.array(df_train.drop(['label'], axis=1).values.tolist())\n",
    "y_train = np.array(df_train['label'].values.tolist())\n",
    "X_test = np.array(df_test.drop(['label'], axis=1).values.tolist())\n",
    "y_test = np.array(df_test['label'].values.tolist())\n",
    "print(\"data_\" + str(i), \"training data size:\", len(y_train), \"test data size:\", len(y_test))\n",
    "\n",
    "X_train_train, X_valid, y_train_train, y_valid = train_test_split(X_train, y_train, train_size = 0.75, random_state = 42)\n",
    "print(len(X_train_train), len(X_valid), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "train: 0.8709677419354839\n",
      "valid 0.6372007366482505\n",
      "test 0.6422764227642277\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'weighting', \n",
    "    'categorical_encoding:__choice__': 'one_hot_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'median', \n",
    "    'preprocessor:__choice__': \n",
    "    'feature_agglomeration', \n",
    "    'rescaling:__choice__': 'none', \n",
    "    'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'entropy', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.9950088003474201, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 6, \n",
    "    'classifier:random_forest:min_samples_split': 7, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
    "    'classifier:random_forest:n_estimators': 100, \n",
    "    'preprocessor:feature_agglomeration:affinity': 'euclidean', \n",
    "    'preprocessor:feature_agglomeration:linkage': 'complete', \n",
    "    'preprocessor:feature_agglomeration:n_clusters': 91, \n",
    "    'preprocessor:feature_agglomeration:pooling_func': 'max', \n",
    "    'categorical_encoding:one_hot_encoding:minimum_fraction': 0.0012037695802164811},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('original:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data disabled:\n",
      "train: 0.8562037797863599\n",
      "valid 0.6013986013986015\n",
      "test 0.5801526717557253\n"
     ]
    }
   ],
   "source": [
    "# disable data processing\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'none', \n",
    "    'categorical_encoding:__choice__': 'no_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'median', \n",
    "    'preprocessor:__choice__': 'feature_agglomeration', \n",
    "    'rescaling:__choice__': 'none', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'entropy', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.9950088003474201, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 6, \n",
    "    'classifier:random_forest:min_samples_split': 7, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
    "    'classifier:random_forest:n_estimators': 100, \n",
    "    'preprocessor:feature_agglomeration:affinity': 'euclidean', \n",
    "    'preprocessor:feature_agglomeration:linkage': 'complete', \n",
    "    'preprocessor:feature_agglomeration:n_clusters': 91, \n",
    "    'preprocessor:feature_agglomeration:pooling_func': 'max', \n",
    "    },\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('data disabled:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature disabled:\n",
      "train: 0.8571428571428572\n",
      "valid 0.5925925925925926\n",
      "test 0.5721649484536082\n"
     ]
    }
   ],
   "source": [
    "# disable feature processing\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'none', \n",
    "    'categorical_encoding:__choice__': 'no_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'median', \n",
    "    'preprocessor:__choice__': 'no_preprocessing', \n",
    "    'rescaling:__choice__': 'none', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'entropy', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.9950088003474201, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 6, \n",
    "    'classifier:random_forest:min_samples_split': 7, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
    "    'classifier:random_forest:n_estimators': 100},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('feature disabled:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter disabled:\n",
      "train: 1.0\n",
      "valid 0.6198547215496368\n",
      "test 0.5898123324396781\n"
     ]
    }
   ],
   "source": [
    "# disable tuned parameter\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'none', \n",
    "    'categorical_encoding:__choice__': 'no_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'median', \n",
    "    'preprocessor:__choice__': 'no_preprocessing', \n",
    "    'rescaling:__choice__': 'none', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'gini', #'entropy', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.5, #0.9950088003474201, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 1, #6, \n",
    "    'classifier:random_forest:min_samples_split': 2, #7, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
    "    'classifier:random_forest:n_estimators': 100},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('parameter disabled:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_7 training data size: 8193 test data size: 2049\n",
      "6144 2049 2049\n"
     ]
    }
   ],
   "source": [
    "# analysis for dataset 7:\n",
    "\n",
    "i = 7\n",
    "\n",
    "train_path = './02-feature-extract-ori/features/ft_' + str(i) + '_train.csv'\n",
    "test_path = './02-feature-extract-ori/features/ft_' + str(i) + '_test.csv'\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "        \n",
    "X_train = np.array(df_train.drop(['label'], axis=1).values.tolist())\n",
    "y_train = np.array(df_train['label'].values.tolist())\n",
    "X_test = np.array(df_test.drop(['label'], axis=1).values.tolist())\n",
    "y_test = np.array(df_test['label'].values.tolist())\n",
    "print(\"data_\" + str(i), \"training data size:\", len(y_train), \"test data size:\", len(y_test))\n",
    "\n",
    "X_train_train, X_valid, y_train_train, y_valid = train_test_split(X_train, y_train, train_size = 0.75, random_state = 42)\n",
    "print(len(X_train_train), len(X_valid), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "train: 0.9769736842105263\n",
      "valid 0.7739938080495355\n",
      "test 0.7893333333333333\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'weighting', \n",
    "    'categorical_encoding:__choice__': 'one_hot_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'most_frequent', \n",
    "    'preprocessor:__choice__': 'select_percentile_classification', \n",
    "    'rescaling:__choice__': 'robust_scaler', \n",
    "    'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'gini', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.9008519355763185, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 2, \n",
    "    'classifier:random_forest:min_samples_split': 6, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0, \n",
    "    'classifier:random_forest:n_estimators': 100, \n",
    "    'preprocessor:select_percentile_classification:percentile': 55.84285592896699, \n",
    "    'preprocessor:select_percentile_classification:score_func': 'f_classif', \n",
    "    'rescaling:robust_scaler:q_max': 0.9194022794180152, \n",
    "    'rescaling:robust_scaler:q_min': 0.19454891546620004, \n",
    "    'categorical_encoding:one_hot_encoding:minimum_fraction': 0.07845205738658005},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('original:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "train: 0.9349955476402494\n",
      "valid 0.7848101265822784\n",
      "test 0.7977528089887641\n"
     ]
    }
   ],
   "source": [
    "# data disabled\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'none', \n",
    "    'categorical_encoding:__choice__': 'no_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'most_frequent', \n",
    "    'rescaling:__choice__': 'none',  \n",
    "    'preprocessor:__choice__': 'select_percentile_classification', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'gini', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.9008519355763185, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 2, \n",
    "    'classifier:random_forest:min_samples_split': 6, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0, \n",
    "    'classifier:random_forest:n_estimators': 100, \n",
    "    'preprocessor:select_percentile_classification:percentile': 55.84285592896699, \n",
    "    'preprocessor:select_percentile_classification:score_func': 'f_classif'},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('original:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "train: 0.940550133096717\n",
      "valid 0.7834394904458598\n",
      "test 0.7853107344632768\n"
     ]
    }
   ],
   "source": [
    "# feature disabled\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'none', \n",
    "    'categorical_encoding:__choice__': 'no_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'most_frequent', \n",
    "    'preprocessor:__choice__': 'no_preprocessing', \n",
    "    'rescaling:__choice__': 'none', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'gini', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.9008519355763185, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 2, \n",
    "    'classifier:random_forest:min_samples_split': 6, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0, \n",
    "    'classifier:random_forest:n_estimators': 100},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('original:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "train: 0.9991589571068125\n",
      "valid 0.7788778877887789\n",
      "test 0.783625730994152\n"
     ]
    }
   ],
   "source": [
    "# parameter disabled\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'none', \n",
    "    'categorical_encoding:__choice__': 'no_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'most_frequent', \n",
    "    'preprocessor:__choice__': 'no_preprocessing', \n",
    "    'rescaling:__choice__': 'none', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'gini', #'entropy', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.5, #0.9950088003474201, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 1, #6, \n",
    "    'classifier:random_forest:min_samples_split': 2, #7, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
    "    'classifier:random_forest:n_estimators': 100},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('original:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_8 training data size: 7659 test data size: 1916\n",
      "5744 1915 1916\n"
     ]
    }
   ],
   "source": [
    "# analysis for dataset 8:\n",
    "\n",
    "i = 8\n",
    "\n",
    "train_path = './02-feature-extract-ori/features/ft_' + str(i) + '_train.csv'\n",
    "test_path = './02-feature-extract-ori/features/ft_' + str(i) + '_test.csv'\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "        \n",
    "X_train = np.array(df_train.drop(['label'], axis=1).values.tolist())\n",
    "y_train = np.array(df_train['label'].values.tolist())\n",
    "X_test = np.array(df_test.drop(['label'], axis=1).values.tolist())\n",
    "y_test = np.array(df_test['label'].values.tolist())\n",
    "print(\"data_\" + str(i), \"training data size:\", len(y_train), \"test data size:\", len(y_test))\n",
    "\n",
    "X_train_train, X_valid, y_train_train, y_valid = train_test_split(X_train, y_train, train_size = 0.75, random_state = 42)\n",
    "print(len(X_train_train), len(X_valid), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "train: 0.9262048192771085\n",
      "valid 0.639344262295082\n",
      "test 0.5621621621621622\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'weighting', \n",
    "    'categorical_encoding:__choice__': 'no_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'median', \n",
    "    'preprocessor:__choice__': 'feature_agglomeration', \n",
    "    'rescaling:__choice__': 'none', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'entropy', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.9008524359169225, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 6, \n",
    "    'classifier:random_forest:min_samples_split': 4, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0, \n",
    "    'classifier:random_forest:n_estimators': 100, \n",
    "    'preprocessor:feature_agglomeration:affinity': 'manhattan', \n",
    "    'preprocessor:feature_agglomeration:linkage': 'average', \n",
    "    'preprocessor:feature_agglomeration:n_clusters': 128, \n",
    "    'preprocessor:feature_agglomeration:pooling_func': 'max'},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('original:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "  \n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data disabled:\n",
      "train: 0.8278388278388278\n",
      "valid 0.5599999999999999\n",
      "test 0.5562913907284768\n"
     ]
    }
   ],
   "source": [
    "# data disabled\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'none', \n",
    "    'categorical_encoding:__choice__': 'no_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'median', \n",
    "    'preprocessor:__choice__': 'feature_agglomeration', \n",
    "    'rescaling:__choice__': 'none', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'entropy', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.9008524359169225, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 6, \n",
    "    'classifier:random_forest:min_samples_split': 4, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0, \n",
    "    'classifier:random_forest:n_estimators': 100, \n",
    "    'preprocessor:feature_agglomeration:affinity': 'manhattan', \n",
    "    'preprocessor:feature_agglomeration:linkage': 'average', \n",
    "    'preprocessor:feature_agglomeration:n_clusters': 128, \n",
    "    'preprocessor:feature_agglomeration:pooling_func': 'max'},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('data disabled:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature disabled:\n",
      "train: 0.8226691042047533\n",
      "valid 0.5570469798657718\n",
      "test 0.5612903225806452\n"
     ]
    }
   ],
   "source": [
    "# feature disabled\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'none', \n",
    "    'categorical_encoding:__choice__': 'no_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'median', \n",
    "    'preprocessor:__choice__': 'no_preprocessing', \n",
    "    'rescaling:__choice__': 'none', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'entropy', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 0.9008524359169225, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 6, \n",
    "    'classifier:random_forest:min_samples_split': 4, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0, \n",
    "    'classifier:random_forest:n_estimators': 100},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('feature disabled:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trying to set illegal value '5' (type '<class 'int'>') for hyperparameter 'classifier:random_forest:max_features, Type: UniformFloat, Range: [0.0, 1.0], Default: 0.5' (default-value has type '<class 'numpy.float64'>').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-351bd04f400b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;34m'target_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'classification'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       'signed': False}\n\u001b[0m\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/peiwang/anaconda3/lib/python3.7/site-packages/auto_sklearn-0.6.0-py3.7-linux-x86_64.egg/autosklearn/pipeline/classification.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, pipeline, dataset_properties, include, exclude, random_state, init_params)\u001b[0m\n\u001b[1;32m     81\u001b[0m         super().__init__(\n\u001b[1;32m     82\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_properties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             random_state, init_params)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/peiwang/anaconda3/lib/python3.7/site-packages/auto_sklearn-0.6.0-py3.7-linux-x86_64.egg/autosklearn/pipeline/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, pipeline, dataset_properties, include, exclude, random_state, init_params)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_space\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_space\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mConfigSpace/configuration_space.pyx\u001b[0m in \u001b[0;36mConfigSpace.configuration_space.Configuration.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Trying to set illegal value '5' (type '<class 'int'>') for hyperparameter 'classifier:random_forest:max_features, Type: UniformFloat, Range: [0.0, 1.0], Default: 0.5' (default-value has type '<class 'numpy.float64'>')."
     ]
    }
   ],
   "source": [
    "# parameter disabled\n",
    "\n",
    "pipe = SimpleClassificationPipeline({\n",
    "    'balancing:strategy': 'none', \n",
    "    'categorical_encoding:__choice__': 'no_encoding', \n",
    "    'classifier:__choice__': 'random_forest', \n",
    "    'imputation:strategy': 'median', \n",
    "    'preprocessor:__choice__': 'no_preprocessing', \n",
    "    'rescaling:__choice__': 'none', \n",
    "    'classifier:random_forest:bootstrap': 'True', \n",
    "    'classifier:random_forest:criterion': 'gini', \n",
    "    'classifier:random_forest:max_depth': 'None', \n",
    "    'classifier:random_forest:max_features': 5, \n",
    "    'classifier:random_forest:max_leaf_nodes': 'None', \n",
    "    'classifier:random_forest:min_impurity_decrease': 0.0, \n",
    "    'classifier:random_forest:min_samples_leaf': 1, \n",
    "    'classifier:random_forest:min_samples_split': 2, \n",
    "    'classifier:random_forest:min_weight_fraction_leaf': 0.0, \n",
    "    'classifier:random_forest:n_estimators': 100},\n",
    "    dataset_properties={\n",
    "      'task': 1,\n",
    "      'sparse': False,\n",
    "      'multilabel': False,\n",
    "      'multiclass': False,\n",
    "      'target_type': 'classification',\n",
    "      'signed': False}\n",
    "    )\n",
    "\n",
    "pipe.fit(X_train_train, y_train_train)\n",
    "\n",
    "print('parameter disabled:')\n",
    "\n",
    "y_train_train_pred = pipe.predict(X_train_train)\n",
    "print('train:', f1(y_train_train, y_train_train_pred))\n",
    "\n",
    "y_valid_pred = pipe.predict(X_valid)\n",
    "print('valid', f1(y_valid, y_valid_pred))\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print('test', f1(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
